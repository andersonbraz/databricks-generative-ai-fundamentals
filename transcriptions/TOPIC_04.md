# Legal and Ethical Considerations

## Riscos e desafios potenciais

Nesta seção, vamos explorar os potenciais riscos associados à inteligência artificial generativa. Examinaremos considerações legais, éticas e as implicações da interação entre humanos e IA no futuro da força de trabalho e do ambiente de trabalho. Além de seus grandes benefícios potenciais, a IA generativa traz novos riscos e desafios para empresas e sociedade. Houve muitos debates sobre os riscos e benefícios da IA em geral, e você provavelmente já ouviu notícias sobre cientistas e pioneiros da IA emitindo declarações sobre os potenciais riscos dos sistemas de IA para a humanidade. Nesta seção, exploraremos os principais riscos e desafios e proporemos algumas boas práticas para mitigar esses riscos.

Questões legais, como privacidade, segurança e propriedade intelectual, estão entre as preocupações importantes. Desafios éticos surgem de vieses nos dados e algoritmos, além dos riscos associados à desinformação. O impacto da IA na sociedade e na força de trabalho também é um aspecto altamente controverso atualmente. Todos estão se perguntando a mesma coisa: a IA vai substituir meu emprego? Como mostrado neste diagrama, nem todos os riscos têm o mesmo potencial de dano. Além disso, enquanto alguns riscos são relativamente fáceis de enfrentar, outros podem representar desafios maiores para empresas e indivíduos.

Os aspectos legais e éticos da IA generativa estão evoluindo rapidamente, e muitos debates têm surgido em torno deles. Assim, é importante que você considere esses fatores no contexto do seu próprio caso.

## Considerações Legais

Vamos começar com o aspecto legal da IA generativa. O primeiro desafio que a IA generativa trouxe é a preocupação com privacidade. Os modelos atuais de IA generativa carecem de uma função de esquecimento para dados pessoais, pois são treinados em grandes quantidades de dados que podem, inadvertidamente, expor informações pessoais, potencialmente violando os direitos de privacidade dos indivíduos. Portanto, é crucial que as empresas estejam cientes desses riscos e tomem as medidas necessárias para garantir que não violem esses direitos ao construir e usar IA generativa. Aqui estão alguns pontos-chave a considerar para proteger a privacidade dos dados: use sua estratégia de dados existente como base para sua estratégia de privacidade e IA; defina os tipos de consentimento ou permissão que você pode precisar; forneça treinamento aos funcionários sobre práticas de privacidade de dados; estabeleça políticas claras da empresa sobre o uso de ferramentas de IA generativa; desenvolva um plano de violação para lidar com incidentes de privacidade.

Quando usar serviços proprietários prontos, determine que tipo de dados será coletado; entenda se seus dados serão usados para treinar modelos ou compartilhados com terceiros; certifique-se de ter capacidades de linhagem de dados que permitam excluir dados de várias partes do desenvolvimento do modelo, se necessário; avalie se o histórico de interações do usuário é armazenado e garanta a segurança. Além das considerações gerais discutidas, aqui estão algumas boas práticas para garantir a privacidade dos dados: ao processar dados para treinar modelos de IA ou usá-los como entrada, proteja seus dados, normalizando e criptografando adequadamente, e implemente controles de acesso robustos. Isso ajudará a proteger informações sensíveis durante o treinamento, armazenamento e uso. Estabeleça governança: crie um framework para governança de dados e modelos, incluindo práticas como controle de versão, monitoramento, auditoria e definição de uso de dados. Isso garante que você tenha controle sobre seus dados e modelos ao longo de seu ciclo de vida.

Além das preocupações com privacidade, os modelos de IA também apresentam desafios de segurança. Um problema notável é o vazamento de dados. A IA generativa pode memorizar e reproduzir dados de treinamento, levantando preocupações quando informações sensíveis ou confidenciais estão incluídas nos dados de treinamento ou prompts. Um exemplo ilustrativo disso ocorreu na Samsung, onde um funcionário acidentalmente compartilhou segredos da empresa com o ChatGPT, e descobriu-se que o ChatGPT reteve e memorizou essas informações. Outro risco de segurança para modelos de IA generativa é a exploração do modelo por meio de prompts, conhecida como injeção de prompts. Isso acontece quando usuários inserem instruções específicas para manipular o comportamento normal do modelo. No exemplo mostrado, o modelo inicialmente recusa-se a divulgar informações solicitadas, mas, ao modificar o prompt, fornece as informações desejadas. Essa manipulação pode levar a diversas preocupações de segurança, como a geração de código malicioso, instruções ao agente para fornecer informações incorretas ou a revelação de dados confidenciais.

Embora a tecnologia de IA tenha facilitado muitas tarefas, ela também apresenta riscos quando cai em mãos erradas. Indivíduos com intenções maliciosas, como fraudadores e atacantes cibernéticos, podem explorar essa tecnologia para criar conteúdo prejudicial. Especificamente no caso de LLMs, há várias ameaças potenciais a serem observadas: descoberta de vulnerabilidades e geração de exploits; ataques automatizados de fraude ou golpes; ataques de engenharia social personalizados; código malicioso gerado por ferramentas de geração de código; e fácil acesso a conteúdo para planejar ataques ou incitar violência. É importante estar vigilante e implementar medidas de segurança para mitigar esses riscos associados a LLMs e prevenir o uso indevido da tecnologia.

A propriedade de conteúdo gerado por IA e as implicações de direitos autorais dos dados de treinamento usados em modelos de IA permanecem temas controversos, gerando inúmeras discussões. Ao utilizar modelos de IA generativa para fins comerciais, é crucial considerar cuidadosamente os aspectos de propriedade intelectual. Aqui estão duas considerações: os modelos de IA generativa podem ser treinados com dados proprietários e protegidos por direitos autorais; assim como outros softwares, esses modelos estão sujeitos a licenças que ditam seu uso. Para proteger os direitos de propriedade intelectual, garanta o uso adequado do conteúdo gerado, estabelecendo acordos legais e aderindo aos termos e condições das licenças que regem os modelos de IA.

As considerações legais se estendem a novas e emergentes tecnologias, como a IA generativa, e as leis existentes continuam aplicáveis. Processos de tomada de decisão automatizada devem estar atentos a vieses e discriminação para evitar ações regulatórias ou disputas legais para desenvolvedores ou implantadores. Além disso, deve-se ter cuidado ao fazer alegações sobre a funcionalidade ou os resultados de um modelo ou algoritmo. Há também a necessidade de abordar a responsabilidade por produtos, o que pode levar a litígios. A regulamentação hoje é influenciada por leis existentes e por propostas recentes, destinadas a abordar seu impacto. Algumas regulamentações notáveis propostas incluem: o Ato de IA da UE, que propõe um framework regulatório abrangente para governar o desenvolvimento, implantação e uso de sistemas de IA na União Europeia; o Ato de Responsabilidade Algorítmica dos EUA, que visa estabelecer transparência, justiça e responsabilidade em sistemas de decisão automatizada, incluindo os que utilizam IA; a abordagem de regulamentação de IA do Japão de 2023; e as ações de IA responsável da administração Biden-Harris de 2023, que introduziram iniciativas para promover o desenvolvimento e a adoção responsáveis de IA em diversos setores. Além disso, existem regulamentações em nível estadual, como a regulamentação da Califórnia sobre ferramentas de decisão automatizada, que foca na regulação de sistemas de decisão automatizada.

## Interação entre humanos e IA


